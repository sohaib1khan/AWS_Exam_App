[{"id": 1, "question": "Which AWS service is primarily used for storing static files?", "options": ["EC2", "S3", "DynamoDB", "RDS"], "correct_answer": "S3", "explanation": "Amazon S3 (Simple Storage Service) is an object storage service that offers industry-leading scalability, data availability, security, and performance for storing static files."}, {"id": 2, "question": "Which AWS service would you use to run containers?", "options": ["EC2", "S3", "ECS/EKS", "Lambda"], "correct_answer": "ECS/EKS", "explanation": "Amazon ECS (Elastic Container Service) and EKS (Elastic Kubernetes Service) are services designed specifically for running containers in AWS."}, {"id": 3, "question": "A developer will be building a game data feed application which will continuously collect data about player-game interactions and feed the data into your gaming platform. The application uses the Kinesis Client Library to process the data stream from the Amazon Kinesis Data Streams and stores the data to Amazon DynamoDB. It is required that the system should have enough shards and EC2 instances in order to handle failover and adequately process the amount of data coming in and out of the stream.\r\n\r\nWhich of the following ratio of the number of Kinesis shards to EC2 worker instances should the developer implement to achieve the above requirement in the most cost-effective and highly available way?", "options": ["4 shards : 2 instances", "1 shard : 6 instances", "6 shards : 1 instance", "4 shards : 8 instances"], "correct_answer": "4 shards : 2 instances", "explanation": "A stream is composed of one or more shards, each of which provides a fixed unit of capacity. The total capacity of the stream is the sum of the capacities of its shards. The Kinesis Client Library (KCL) ensures that for every shard there is a record processor running and processing that shard. It also tracks the shards in the stream using an Amazon DynamoDB table.\r\n\r\n\r\n\r\nTypically, when you use the KCL, you should ensure that the number of instances does not exceed the number of shards (except for failure standby purposes). Each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard. However, one worker can process any number of shards, so it\u2019s fine if the number of shards exceeds the number of instances.\r\n\r\nSince the question requires the system to smoothly process streaming data, a fair number of shards and instances are required. By launching 4 shards, the stream will have more capacity for reading and writing data. By launching 2 instances, each instance will focus on processing two shards. It also provides high availability in the event that one instance goes down. Therefore, the ratio of 4 shards : 2 instances is the correct answer.\r\n\r\nThe 1 shard : 6 instances ratio is incorrect because having just one shard for the stream will be insufficient and in the event that your incoming data rate increases, this single shard will not be able to handle the load.\r\n\r\nThe 6 shards : 1 instance ratio is incorrect because having just one instance to process multiple shards will be insufficient since the processing capacity of your system will be severely limited. You have to allocate more instances in proportion to the number of open shards in your data stream. Moreover, a single instance is not a highly available option since the application doesn\u2019t have a backup instance to process the shards in the event of an outage.\r\n\r\nThe 4 shards : 8 instances ratio is incorrect because launching more instances than the number of open shards will not improve the processing of the stream as it is only useful for failure standby purposes. Take note that each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard. In addition, this option is not the most cost-effective choice as well.\r\n\r\n"}, {"id": 4, "question": "A developer is deploying a new application to Amazon Elastic Container Service (Amazon ECS). The developer needs to securely store and retrieve different types of variables. These variables include authentication information for a remote API, the URL for the API, and credentials. The authentication information and API URL must be available to all current and future deployed versions of the application across development, testing, and production environments.\r\n\r\nHow should the developer retrieve the variables with the FEWEST application changes? ", "options": ["Update the application to retrieve the variables from AWS Systems Manager Parameter Store. Use unique paths in Parameter Store for each variable in each environment. Store the credentials in AWS Secrets Manager in each environment.", " Update the application to retrieve the variables from AWS Key Management Service (AWS KMS). Store the API URL and credentials as unique keys for each environment. ", " Update the application to retrieve the variables from an encrypted file that is stored with the application. Store the API URL and credentials in unique files for each environment. ", "Update the application to retrieve the variables from each of the deployed environments. Define the authentication information and API URL in the ECS task definition as unique names during the deployment process. "], "correct_answer": "Update the application to retrieve the variables from AWS Systems Manager Parameter Store. Use unique paths in Parameter Store for each variable in each environment. Store the credentials in AWS Secrets Manager in each environment.", "explanation": "A is correct:\r\n\r\n- It uses the appropriate services for the right types of data (Parameter Store for configuration, Secrets Manager for sensitive credentials)\r\n\r\n- It provides a centralized approach that requires minimal application changes\r\n- It supports hierarchical organization for different environments\r\n- It provides robust security controls through IAM\r\n- It enables changes to parameters without application redeployment\r\n\r\nThe application would only need to be updated once to retrieve variables from these services, and then all future changes to the variables would be managed through the services without additional application changes."}, {"id": 5, "question": "A Developer at a company is working on a CloudFormation template to set up resources. Resources will be defined using code and provisioned based on certain conditions defined in the Conditions section.\r\n\r\nWhich section of a CloudFormation template cannot be associated with Condition?", "options": ["Conditions", "Resources", "Outputs", "Parameters"], "correct_answer": "Parameters", "explanation": "Parameters\r\n\r\nParameters enable you to input custom values to your CloudFormation template each time you create or update a stack. Please see this note to understand how to define a parameter in a template:  via - https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html\r\n\r\nThe optional Conditions section contains statements that define the circumstances under which entities are created or configured. For example, you can create a condition and then associate it with a resource or output so that AWS CloudFormation only creates the resource or output if the condition is true.\r\n\r\nYou might use conditions when you want to reuse a template that can create resources in different contexts, such as a test environment versus a production environment. In your template, you can add an EnvironmentType input parameter, which accepts either prod or test as inputs. For the production environment, you might include Amazon EC2 instances with certain capabilities; however, for the test environment, you want to use reduced capabilities to save money.\r\n\r\nConditions cannot be used within the Parameters section. After you define all your conditions, you can associate them with resources and resource properties only in the Resources and Outputs sections of a template.\r\n\r\nPlease review this note for more details:  via - https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html\r\n\r\nPlease visit https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html for more information on the parameter structure.\r\n\r\nIncorrect options:\r\n\r\nResources - Resources section describes the resources that you want to provision in your AWS CloudFormation stacks. You can associate conditions with the resources that you want to conditionally create.\r\n\r\nConditions - You actually define conditions in this section of the CloudFormation template\r\n\r\nOutputs - The optional Outputs section declares output values that you can import into other stacks (to create cross-stack references), return in response (to describe stack calls), or view on the AWS CloudFormation console. For example, you can output the S3 bucket name for a stack to make the bucket easier to find. You can associate conditions with the outputs that you want to conditionally create."}, {"id": 6, "question": "The development team at a company creates serverless solutions using AWS Lambda. Functions are invoked by clients via AWS API Gateway which anyone can access. The team lead would like to control access using a 3rd party authorization mechanism.\r\n\r\nAs a Developer Associate, which of the following options would you recommend for the given use-case?\r\n\r\n\r\n\r\n\r\n\r\n", "options": ["Cognito User Pools", "Lambda Authorizer", "API Gateway User Pools", "IAM permissions with sigv4"], "correct_answer": "Lambda Authorizer", "explanation": "Correct option:\r\n\r\n\"Lambda Authorizer\"\r\n\r\nAn Amazon API Gateway Lambda authorizer (formerly known as a custom authorizer) is a Lambda function that you provide to control access to your API. A Lambda authorizer uses bearer token authentication strategies, such as OAuth or SAML. Before creating an API Gateway Lambda authorizer, you must first create the AWS Lambda function that implements the logic to authorize and, if necessary, to authenticate the caller.\r\n\r\n via - https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html\r\n\r\nIncorrect options:\r\n\r\n\"IAM permissions with sigv4\" - Signature Version 4 is the process to add authentication information to AWS requests sent by HTTP. You will still need to provide permissions but our requirements have a need for 3rd party authentication which is where Lambda Authorizer comes in to play.\r\n\r\n\"Cognito User Pools\" - A Cognito user pool is a user directory in Amazon Cognito. With a user pool, your users can sign in to your web or mobile app through Amazon Cognito, or federate through a third-party identity provider (IdP). Whether your users sign-in directly or through a third party, all members of the user pool have a directory profile that you can access through an SDK. This is managed by AWS, therefore, does not meet our requirements.\r\n\r\n\"API Gateway User Pools\" - This is a made-up option, added as a distractor.\r\n\r\nReference:\r\n\r\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html"}]